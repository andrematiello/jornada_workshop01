![Python](https://img.shields.io/badge/python-3.11%2B-blue)
![Tests](https://img.shields.io/badge/tests-passing-brightgreen)
![License](https://img.shields.io/badge/license-MIT-green)


# Pipeline ETL Modular com Testes e Logging

## Sobre o Projeto

Este projeto possui o principal foco na construÃ§Ã£o padronizada de uma estrutura de projetos e documentaÃ§Ã£o, de modo acessÃ³rio, portanto, com menor preocupaÃ§Ã£o com a sofisticaÃ§Ã£o do ETL, implementa um pipeline ETL modular em Python, dividindo-o em trÃªs etapas principais:

- Extract: leitura e concatenaÃ§Ã£o de mÃºltiplos arquivos Excel.
- Transform: limpeza e normalizaÃ§Ã£o dos dados, exportaÃ§Ã£o para Parquet.
- Load: leitura de Parquet e exportaÃ§Ã£o final para Excel.

Fora observado rigor na documentaÃ§Ã£o e estrutura do projeto.
ApÃ³s cada etapa, o pipeline executa testes unitÃ¡rios com `pytest`.  
No final, executa um teste de integraÃ§Ã£o que valida o sucesso global!ğŸš€ 

Todos os eventos sÃ£o registrados em um arquivo de log gerado automaticamente na pasta `docs/`.
O arquivo armazena todas as etapas da pipeline, dos testes unitÃ¡rios com nome no formato: `docs/log_YYYYMMDD_HHMMSS.log`.

## Fluxo do Pipeline
- Extract â†’ Teste, se ok:
- Transform â†’ Teste, se ok:
- Load â†’ Teste, se ok:
- Teste Final âœ…
- Log gerado ğŸ“„
- FIM ğŸ¯

---

## ComeÃ§ando

### PrÃ©-requisitos

1. Git e Github
VocÃª deve ter o Git instalado em sua mÃ¡quina.
VocÃª tambÃ©m deve ter uma conta no GitHub.

2. Pyenv
Pyenv: Ã‰ usado para gerenciar versÃµes do Python.
[InstruÃ§Ãµes de instalaÃ§Ã£o do Pyenv aqui](https://github.com/pyenv/pyenv#installation).
Vamos usar nesse projeto o Python 3.11.3.
Para usuÃ¡rios Windows, Ã© recomendado assistirem esse tutorial [Youtube](https://www.youtube.com/watch?v=TkcqjLu1dgA).

3. Poetry
Poetry: Este projeto utiliza Poetry para gerenciamento de dependÃªncias.
[InstruÃ§Ãµes de instalaÃ§Ã£o do Poetry aqui](https://python-poetry.org/docs/#installation).
Se vocÃª Ã© usuÃ¡rio Windows, recomendo assistir esse vÃ­deo: [Youtube](https://www.youtube.com/watch?v=BuepZYn1xT8).
Que instala o Python, Poetry e VSCode. Mas um simples comando PIP INSTALL POETRY jÃ¡ resolve.

### InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/andrematiello/jornada_workshop01
```

2. Acesse o dir:

```bash
cd workshop
```

3. Configure a versÃ£o correta do Python:
```bash
pyenv install 3.11.5
pyenv local 3.11.5
```

4. Configure o Poetry para usar o Python 3.11.5 e ative o ambiente virtual:
```bash
poetry env use 3.11.5
poetry shell
```

5. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

### Como rodar o projeto:

1. Execute o comando para ver a documentaÃ§Ã£o do projeto:

```bash
task doc
```

2. Execute o pipeline:
```bash
python -m app.main`
```

3. Verifique na pasta data/output se o arquivo foi gerado corretamente.

---

## Como rodar os testes:
Todos os testes usam a biblioteca pytest.

#### Individualmente:

- Teste do extract:
```bash
pytest tests/test_extract.py
```

- Teste do transform:
```bash
pytest tests/test_transform.py
```

- Teste do load:
```bash
pytest tests/test_load.py
```

- Teste de toda pipeline:
```bash
pytest tests/test_pipeline.py
```

### Todos de uma vez:

```bash
pytest
```

---

## Tecnologias utilizadas
- Python 3.11+
- Pyenv
- Poetry
- Git e Github

## Bibliotecas utilizadas
- Pandas: manipulaÃ§Ã£o de dados.
- Pyarrow: leitura e escrita Parquet.
- Pytest: testes automatizados.

---

##  CriaÃ§Ã£o do arquivo de requirements.txt
- pandas>=1.0
- pyarrow>=9.0
- pytest>=7.0

---

## ComentÃ¡rios acerca do projeto:

### Agora vocÃª tem:
ğŸ”¹ Pipeline robusto
ğŸ”¹ Testes intermediÃ¡rios
ğŸ”¹ Logs completos
ğŸ”¹ DocumentaÃ§Ã£o top!
ğŸ”¹ requirements.txt

### Este projeto entrega um pipeline ETL completo e profissional, seguindo as melhores prÃ¡ticas de Engenharia de Dados, com foco em:
ğŸ”¹ Modularidade â€” cada etapa separada com responsabilidade Ãºnica: Extract, Transform e Load.
ğŸ”¹ Testabilidade â€” testes automatizados com pytest em cada etapa, garantindo qualidade e seguranÃ§a na evoluÃ§Ã£o do cÃ³digo.
ğŸ”¹ Observabilidade â€” sistema de logging estruturado, com geraÃ§Ã£o automÃ¡tica de arquivos de log identificados por data e hora, permitindo rastreabilidade completa de cada execuÃ§Ã£o.
ğŸ”¹ AutomaÃ§Ã£o â€” execuÃ§Ã£o sequencial e validada de todo o processo, com parada imediata em caso de falha, evitando propagaÃ§Ã£o de erros.
ğŸ”¹ DocumentaÃ§Ã£o clara â€” orientaÃ§Ãµes objetivas sobre execuÃ§Ã£o, estrutura do projeto e fluxo de dados, facilitando manutenÃ§Ã£o e escalabilidade.
ğŸ”¹ EstÃ©tica e usabilidade â€” enriquecido com emojis e mensagens amigÃ¡veis para tornar a execuÃ§Ã£o mais visual e intuitiva.

## Principais caracterÃ­sticas tÃ©cnicas:

### ğŸ”’ SeguranÃ§a e Controle:
ValidaÃ§Ã£o automatizada de cada etapa via testes unitÃ¡rios com pytest, assegurando que falhas sejam identificadas e tratadas de forma imediata e controlada.
Arquitetura defensiva: o pipeline interrompe automaticamente a execuÃ§Ã£o em caso de erro, evitando propagaÃ§Ã£o de inconsistÃªncias.

### ğŸ› ï¸ Robustez e Escalabilidade:
Estrutura modular orientada a funÃ§Ãµes especÃ­ficas, garantindo manutenibilidade e facilidade de extensÃ£o para novos requisitos ou integraÃ§Ãµes.
Logging estruturado, com timestamp de execuÃ§Ã£o e status de cada etapa, viabilizando rastreabilidade completa e facilitando auditorias.

### ğŸ“Š Observabilidade e TransparÃªncia:
Todos os eventos e operaÃ§Ãµes sÃ£o registrados em logs persistentes, gerados automaticamente e armazenados em docs/, permitindo uma visÃ£o clara da execuÃ§Ã£o e apoio a processos de compliance e forense.

### ğŸš€ Entrega de Valor:
AutomaÃ§Ã£o de todo o fluxo ETL: desde a ingestÃ£o atÃ© a exportaÃ§Ã£o dos dados tratados e validados, com garantias explÃ­citas de qualidade e confiabilidade.
MitigaÃ§Ã£o de riscos operacionais com testes intermediÃ¡rios, evitando a entrega de dados corrompidos ou incompletos.
PreparaÃ§Ã£o de dados em formatos otimizados (Parquet e Excel), prontos para anÃ¡lise, reporting ou integraÃ§Ã£o com sistemas de inteligÃªncia.

---

Projeto inspirado no workshop 01 da Jornada de Dados, com adaptaÃ§Ãµes;
Projeto realizado com apoio de InteligÃªncia Artificial (ChatGPT);

## Para dÃºvidas, sugestÃµes ou feedbacks:

### AndrÃ© Matiello C. Caramanti - [matiello.andre@hotmail.com](mailto:matiello.andre@hotmail.com)

 ## âœ…"Este pipeline nÃ£o apenas executa, mas valida, registra e garante a qualidade dos dados de ponta a ponta, conforme as melhores prÃ¡ticas de Engenharia de Dados."